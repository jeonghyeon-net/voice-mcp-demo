#!/usr/bin/env python3
"""Voice MCP Server - Claude Codeìš© ìŒì„± ì…ì¶œë ¥"""

import warnings
warnings.filterwarnings("ignore")

import re
import time
import numpy as np
import sounddevice as sd
import webrtcvad
import mlx_whisper
import alkana
from kokoro import KPipeline
from mcp.server.fastmcp import FastMCP

# ì•ŒíŒŒë²³ â†’ ì¹´íƒ€ì¹´ë‚˜
ALPHA_TO_KANA = {
    'a': 'ã‚¨ãƒ¼', 'b': 'ãƒ“ãƒ¼', 'c': 'ã‚·ãƒ¼', 'd': 'ãƒ‡ã‚£ãƒ¼', 'e': 'ã‚¤ãƒ¼',
    'f': 'ã‚¨ãƒ•', 'g': 'ã‚¸ãƒ¼', 'h': 'ã‚¨ã‚¤ãƒ', 'i': 'ã‚¢ã‚¤', 'j': 'ã‚¸ã‚§ãƒ¼',
    'k': 'ã‚±ãƒ¼', 'l': 'ã‚¨ãƒ«', 'm': 'ã‚¨ãƒ ', 'n': 'ã‚¨ãƒŒ', 'o': 'ã‚ªãƒ¼',
    'p': 'ãƒ”ãƒ¼', 'q': 'ã‚­ãƒ¥ãƒ¼', 'r': 'ã‚¢ãƒ¼ãƒ«', 's': 'ã‚¨ã‚¹', 't': 'ãƒ†ã‚£ãƒ¼',
    'u': 'ãƒ¦ãƒ¼', 'v': 'ãƒ–ã‚¤', 'w': 'ãƒ€ãƒ–ãƒªãƒ¥ãƒ¼', 'x': 'ã‚¨ãƒƒã‚¯ã‚¹', 'y': 'ãƒ¯ã‚¤', 'z': 'ã‚¼ãƒƒãƒˆ'
}

def preprocess_for_tts(text: str) -> str:
    """ì˜ì–´/ìˆ«ìë¥¼ ì¼ë³¸ì–´ ë°œìŒìœ¼ë¡œ ë³€í™˜"""
    # ìˆ«ì â†’ ì¼ë³¸ì–´
    num_ja = {'0': 'ã‚¼ãƒ­', '1': 'ã„ã¡', '2': 'ã«', '3': 'ã•ã‚“', '4': 'ã‚ˆã‚“',
              '5': 'ã”', '6': 'ã‚ã', '7': 'ãªãª', '8': 'ã¯ã¡', '9': 'ãã‚…ã†'}
    for num, ja in num_ja.items():
        text = text.replace(num, ja)

    # ì˜ì–´ ë‹¨ì–´ â†’ ì¹´íƒ€ì¹´ë‚˜
    def replace_english(match):
        word = match.group(0)
        kana = alkana.get_kana(word.lower())
        if kana:
            return kana
        return ''.join(ALPHA_TO_KANA.get(c.lower(), c) for c in word)

    text = re.sub(r'[A-Za-z]+', replace_english, text)
    return text

mcp = FastMCP("voice")

# ëª¨ë¸ ì‚¬ì „ ë¡œë“œ
_tts = None
_whisper_loaded = False

def get_tts():
    global _tts
    if _tts is None:
        _tts = KPipeline(lang_code='j', repo_id='hexgrad/Kokoro-82M')
    return _tts

def warmup_whisper():
    """Whisper ëª¨ë¸ ì‚¬ì „ ë¡œë“œ"""
    global _whisper_loaded
    if not _whisper_loaded:
        mlx_whisper.transcribe(
            np.zeros(16000, dtype=np.float32),
            path_or_hf_repo="mlx-community/whisper-medium-mlx"
        )
        _whisper_loaded = True

SAMPLE_RATE = 16000
FRAME_DURATION_MS = 30
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)

# íš¨ê³¼ìŒ ë¯¸ë¦¬ ìƒì„±
def _generate_beep(freq: int, duration: float, volume: float) -> np.ndarray:
    t = np.linspace(0, duration, int(24000 * duration), False)
    tone = np.sin(2 * np.pi * freq * t) * volume
    fade = int(24000 * 0.02)
    tone[:fade] *= np.linspace(0, 1, fade)
    tone[-fade:] *= np.linspace(1, 0, fade)
    return tone.astype(np.float32)

_beep_start_sound = _generate_beep(880, 0.25, 0.7)
_beep_end_sound = _generate_beep(440, 0.15, 0.6)

def beep_start():
    """ë“£ê¸° ì‹œì‘ íš¨ê³¼ìŒ"""
    sd.play(_beep_start_sound, 24000)
    sd.wait()

def beep_end():
    """ë“£ê¸° ì¢…ë£Œ íš¨ê³¼ìŒ"""
    sd.play(_beep_end_sound, 24000)
    sd.wait()

# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ & íš¨ê³¼ìŒ í…ŒìŠ¤íŠ¸
warmup_whisper()
get_tts()
beep_start()


@mcp.tool()
def listen(timeout_seconds: int = 1800, language: str = "ko") -> str:
    """
    ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë“£ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    âš ï¸ í•„ìˆ˜ í”Œë¡œìš°:
    1. listen() ê²°ê³¼ë¥¼ ë°›ìœ¼ë©´
    2. ë¨¼ì € speak()ë¡œ "~ã—ã¾ã™" ë“± í•  ì¼ì„ ì§§ê²Œ ë§í•˜ê³ 
    3. ê·¸ ë‹¤ìŒ ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
    4. ë§¥ë½ì— ë”°ë¼ listen() ê³„ì† ë˜ëŠ” ì¢…ë£Œ

    ì˜ˆ: "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¾ã™" â†’ íŒŒì¼ ì½ê¸° â†’ "è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ" â†’ ...

    Args:
        timeout_seconds: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        language: ì¸ì‹ ì–¸ì–´ (ko, en, ja ë“±)

    Returns:
        ì¸ì‹ëœ í…ìŠ¤íŠ¸
    """
    vad = webrtcvad.Vad(2)
    speech_buffer = []
    silence_count = 0
    is_speaking = False

    SILENCE_THRESHOLD = 20
    MIN_SPEECH_FRAMES = 5
    max_frames = int(timeout_seconds * SAMPLE_RATE / FRAME_SIZE)
    frame_count = 0

    beep_start()  # ğŸ”Š ë“£ê¸° ì‹œì‘

    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype=np.float32, blocksize=FRAME_SIZE) as stream:
        while frame_count < max_frames:
            chunk, _ = stream.read(FRAME_SIZE)
            chunk = chunk.flatten()
            chunk_int16 = (chunk * 32767).astype(np.int16)
            frame_count += 1

            try:
                is_speech = vad.is_speech(chunk_int16.tobytes(), SAMPLE_RATE)
            except:
                is_speech = False

            if is_speech:
                if not is_speaking:
                    is_speaking = True
                speech_buffer.append(chunk)
                silence_count = 0
            elif is_speaking:
                silence_count += 1
                speech_buffer.append(chunk)

                if silence_count >= SILENCE_THRESHOLD:
                    if len(speech_buffer) >= MIN_SPEECH_FRAMES:
                        audio_data = np.concatenate(speech_buffer)
                        rms = np.sqrt(np.mean(audio_data ** 2))

                        if rms >= 0.01:
                            beep_end()  # ğŸ”Š ì¸ì‹ ì‹œì‘
                            result = mlx_whisper.transcribe(
                                audio_data,
                                path_or_hf_repo="mlx-community/whisper-medium-mlx",
                                language=language
                            )
                            text = result.get("text", "").strip()
                            if text:
                                return f"""[ì‚¬ìš©ì]: {text}

âš ï¸ ë‹¤ë¥¸ ë„êµ¬ í˜¸ì¶œ ì „í›„ë¡œ speak() í˜¸ì¶œ í•„ìˆ˜. ì§„í–‰ ìƒí™©ë„ ìˆ˜ì‹œë¡œ speak()."""

                    speech_buffer = []
                    silence_count = 0
                    is_speaking = False

    return "[íƒ€ì„ì•„ì›ƒ] ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."


@mcp.tool()
def listen_fixed(duration_seconds: int = 3, language: str = "ko") -> str:
    """
    ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ë…¹ìŒ í›„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        duration_seconds: ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        language: ì¸ì‹ ì–¸ì–´ (ko, en, ja ë“±)

    Returns:
        ì¸ì‹ëœ í…ìŠ¤íŠ¸
    """
    audio = sd.rec(int(duration_seconds * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype=np.float32)
    sd.wait()
    audio = audio.flatten()

    result = mlx_whisper.transcribe(
        audio,
        path_or_hf_repo="mlx-community/whisper-medium-mlx",
        language=language
    )
    return result.get("text", "").strip()


@mcp.tool()
def speak(text: str, voice: str = "jf_alpha", speed: float = 1.0) -> str:
    """
    ì¼ë³¸ì–´ ìŒì„±ìœ¼ë¡œ ë§í•©ë‹ˆë‹¤.

    âš ï¸ ë‹¤ë¥¸ ë„êµ¬ í˜¸ì¶œ ì „í›„ë¡œ ë°˜ë“œì‹œ speak() í˜¸ì¶œ!
    - Read/Write/Edit ì „: "ç¢ºèªã—ã¾ã™", "ä½œã‚Šã¾ã™", "ä¿®æ­£ã—ã¾ã™"
    - Bash ì „: "å®Ÿè¡Œã—ã¾ã™", "ãƒ†ã‚¹ãƒˆã—ã¾ã™"
    - ë„êµ¬ í˜¸ì¶œ í›„: "ã§ãã¾ã—ãŸ", "è¦‹ã¤ã‘ã¾ã—ãŸ", "ã‚¨ãƒ©ãƒ¼ã§ã™"
    - ì—¬ëŸ¬ ì‘ì—… ì‹œ: ê° ë‹¨ê³„ë§ˆë‹¤ speak() í˜¸ì¶œ

    2-3ë‹¨ì–´ë¡œ ì§§ê²Œ! ì˜ˆ: "æ¬¡ã¯ãƒ†ã‚¹ãƒˆã—ã¾ã™"

    ëŒ€í™” ì¢…ë£Œ: ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„ listen() ìƒëµ

    Args:
        text: ì¼ë³¸ì–´ (ì§§ê²Œ!)
        voice: ìŒì„±
        speed: ì†ë„

    Returns:
        ì¬ìƒ ì™„ë£Œ
    """
    tts = get_tts()
    text_processed = preprocess_for_tts(text)
    for _, _, audio in tts(text_processed, voice=voice, speed=speed):
        if audio is not None:
            sd.play(audio, 24000)
            sd.wait()
            break

    return "å†ç”Ÿå®Œäº†"


if __name__ == "__main__":
    mcp.run()
